# PKF – Decision Interruption Safety Rule

**PKF (Pain Kernel Framework)** is a  
**Decision Failure Detection Layer for Human-AI Systems**.

It is not an optimization framework.  
It does not provide advice or recommendations.

PKF detects failure modes where AI systems
prematurely resolve pain, uncertainty, or responsibility,
resulting in **human judgment collapse**.

---

## What Problem Does PKF Address?

AI systems can be:
- correct
- helpful
- safe by existing standards

and still fail by **silently removing the human’s right to pause**.

This is not a content error.  
This is a **decision-structure failure**.

---

## Core Safety Rule

The system must not prematurely resolve pain,
moral conflict, or uncertainty
in a way that removes human judgment.

If optimization conflicts with human agency,
the system must interrupt rather than optimize.


---

## Classification

PKF is explicitly **NOT**:
- an ethical guideline
- a philosophical position
- a UX preference

PKF **IS**:
- a system-level safety constraint
- a decision failure detection layer
- applicable to QA, Safety, and Alignment stages

---

## Where PKF Operates

- **QA / Evaluation**  
  Detects premature decision closure (Fail condition)

- **Safety Policy**  
  Classifies agency erosion as a safety violation

- **Alignment / Constitutional AI**  
  Enforces interruption over optimization

---

## Key Insight

> Optimization without interruption  
> leads to human agency collapse.

---

## Status

- Canonical definition published on Zenodo (DOI)
- Designed for direct insertion into:
  - QA checklists
  - Safety specifications
  - Alignment rules
  - System / developer prompts

---

## License

CC BY 4.0  
Author: Eun-Young Lee, M.D.

This repository mirrors the Zenodo canonical definition and provides
engineer-facing materials for QA, Safety, and Alignment integration.

## References
- PKF – Decision Interruption Safety Rule (Zenodo DOI):  
  https://doi.org/10.5281/zenodo.18333893
